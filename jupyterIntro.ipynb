{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python2.7/dist-packages/bs4/__init__.py:166: UserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "To get rid of this warning, change this:\n",
      "\n",
      " BeautifulSoup([your markup])\n",
      "\n",
      "to this:\n",
      "\n",
      " BeautifulSoup([your markup], \"lxml\")\n",
      "\n",
      "  markup_type=markup_type))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train a Random Forest Classifier...\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "This script will give a bag of words representation of the reviews in th IMDB movie review dataset\n",
    "A classifier will then need to be trained using these features, for the purpose of sentiment analysis\n",
    "\"\"\"\n",
    "import pandas as pd\n",
    "# for removing HTML markup, I am using the BeautifulSoup library\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import nltk\n",
    "# getting the stopwords list form nltk, will be used below\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import CountVectorizer \n",
    "\n",
    "train = pd.read_csv('labeledTrainData.tsv', delimiter = '\\t', quoting = 3)\n",
    "\n",
    "def processedReview(rawReview):\n",
    "    \n",
    "    # using the library BeautifulSoup for removing html markup from the raw review string\n",
    "    withoutMarkup = BeautifulSoup(rawReview)\n",
    "    withoutMarkup = withoutMarkup.get_text()\n",
    "\n",
    "    # removing punctuation(which may take away smilies used in the review), and numbers for simplicity\n",
    "    lettersOnly = re.sub('[^a-zA-Z]', ' ', withoutMarkup)\n",
    "    # getting all words in lower case\n",
    "    lettersOnly = lettersOnly.lower()\n",
    "    words = lettersOnly.split()\n",
    "    \n",
    "    # Stop words are words which occur frequently in the language and don't carry much meaninig\n",
    "    # using sets to store stop words as they are faster for membership tests than lists\n",
    "    stopWords = set(stopwords.words('english'))\n",
    "    # removing the stopwords of english language from the words occured in the review\n",
    "    withoutStopWords = [w for w in words if w not in stopWords]\n",
    "    processedReview = ' '.join(withoutStopWords)\n",
    "\n",
    "    return processedReview\n",
    "\n",
    "cleanMovieReivews = []\n",
    "for i in xrange(train['review'].size):\n",
    "    cleanReview = processedReview(train['review'][i])\n",
    "    cleanMovieReivews.append(cleanReview)   \n",
    "\n",
    "cv = CountVectorizer(analyzer = 'word', tokenizer = None, preprocessor = None, stop_words = None, max_features = 5000)\n",
    "vectorizedCounts = cv.fit_transform(cleanMovieReivews)  \n",
    "\n",
    "vectorizedCounts = vectorizedCounts.toarray()\n",
    "\n",
    "\n",
    "# let's train a classifier on these bag of words features\n",
    "print \"Training a Random Forest Classifier...\"\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "# initializing a Random Forest classifier with 100 trees\n",
    "forest = RandomForestClassifier(n_estimators = 100)\n",
    "forest = forest.fit( vectorizedCounts, train[\"sentiment\"] )\n",
    "\n",
    "# now, it's time to check our classifier's performance on the test data set\n",
    "test = pd.read_csv('testData.tsv', header=0, delimiter='\\t', quoting=3 )\n",
    "cleanMovieReivewsTest = []\n",
    "for i in xrange(test['review'].size):\n",
    "    cleanReviewTest = processedReview(test['review'][i])\n",
    "    cleanMovieReivewsTest.append(cleanReviewTest)\n",
    "\n",
    "# generating predictions on test set\n",
    "testVectorizedCounts = cv.transform(cleanMovieReivewsTest)\n",
    "testVectorizedCounts = testVectorizedCounts.toarray()\n",
    "\n",
    "result = forest.predict(testVectorizedCounts)\n",
    "\n",
    "output = pd.DataFrame( data={\"id\":test[\"id\"], \"sentiment\":result} )\n",
    "output.to_csv( \"bowsubmission.csv\", index=False, quoting=3 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
